library(vcd)
library(dplyr)
library(lubridate)
library(stringr)

data = read.csv('data/tickets-first-line2.csv')
data$create_date <- str_replace_all(data$create_date, "T", " ")
data$create_date <- sort(as_datetime(data$create_date))
data$by_hour = floor_date(data$create_date, 'hour')
data$by_30 = floor_date(data$create_date, '30 mins')
data$by_10 = floor_date(data$create_date, '10 mins')
data$by_1 = floor_date(data$create_date, '1 mins')

flow_12 = filter(data, hour(create_date) >= 10 & hour(create_date) <= 19 & day(create_date) == 4)
flow_12_data = flow_12 %>% group_by(by_1) %>% summarise(count = n())
flow_12_gf = goodfit(flow_12_data$count, type = "poisson", method = "ML")
summary(flow_12_gf)
chisq.test(flow_12_gf$observed, p = flow_12_gf$fitted/sum(flow_12_gf$fitted))
plot(flow_12_gf)

# https://stats.stackexchange.com/questions/178426/r-how-do-the-methods-in-goodfit-package-vcd-calculate-degrees-of-freedom
# p-value > 0.05 - нулевую гипотезу не отклоняем
# p-value < 0.05 - нулевую гипотезу отклоняем

# https://towardsdatascience.com/one-proportion-and-goodness-of-fit-test-in-r-and-by-hand-8c7997013c84
# H0: there is no significant difference between the observed and the expected frequencies
# H1: there is a significant difference between the observed and the expected frequencies
# The p-value is 0.601 so, at the 5% significance level, we do not reject the null hypothesis that the observed and expected frequencies are equal.

flow_12_data

dummy <- rnbinom(200, size = 1.5, prob = 0.8)
gf <- goodfit(dummy, type = "nbinomial", method = "ML")
summary(gf)
plot(gf)
dummy
